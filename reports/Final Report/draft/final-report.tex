\documentclass[a4paper,10pt]{article}
\usepackage{graphicx,wrapfig,hyperref}
\usepackage[hmargin=3.5cm,vmargin=3.0cm]{geometry}
\usepackage{amsmath}

\begin{document}

\title{TI2800 Contextproject - My Cultural Heritage\\ Final Report}
\author{Sjoerd van Bekhoven\\ Tim Eversdijk \\ Herman Blanken \\ Rutger Plak \and 4014774 \\ 4005562 \\ 4078624 \\ 1358375}

\maketitle
\setcounter{page}{0}
\thispagestyle{empty}
\vspace{10cm}
		\begin{figure}[ht!]
				\centering
				\includegraphics[width=\textwidth]{cultuurapp-logo.png}
			\end{figure}
\clearpage

\tableofcontents

\clearpage

%
%
% INLEIDING
%
%
\section{Inleiding}
In dit verslag wordt de ontwikkeling van CultuurApp uitgewerkt. Zowel de problemen en tekortkomingen die we vooraf hebben geconstateerd als de oplossingen die we hiervoor hebben gevonden. Daarnaast worden enkele highlights van CultuurApp besproken en uitgewerkt. Omdat CultuurApp door samenwerking van een team tot stand is gekomen, zal er ook gereflecteerd worden op de samenwerking, zowel in het algemeen als persoonlijk.

%
%
% PROBLEMEN
%
%
\section{Problemen / Tekortkomingen}
	\subsection{Niet toeristgericht}
	Toeristen zoeken en surfen op het internet met een ander doel dan bijvoorbeeld wetenschappers of studenten die zoeken naar informatie. Toeristen zijn over het algemeen minder geinteresseerd in gedetailleerde informatie en willen een overzicht krijgen van een bepaalde omgeving. Op monument-gerelateerde websites is nu vooral gedetailleerde informatie te zien over het monument zelf en ontbreekt alle praktische informatie, zoals het weer bij het monument en restaurants en foto's in de omgeving, maar ook een 'trigger' om meer monumenten te bekijken. De huidige systemen missen aantrekkelijkheid, waardoor de toerist niet gemotiveerd wordt om door te kijken en meer aantrekkelijke monumenten te vinden. Daarnaast zijn er geen systemen die de Nederlandse monumenten ook toegankelijk maken voor buitenlandse toeristen, omdat alle monument-gerelateerde websites in het Nederlands zijn.
	
	\subsection{Incomplete dataset}
	De dataset die is aangeleverd door de leiding van het project bestaat uit $\pm$ 25.000 monumenten. Van deze monumenten zijn er $\pm$ 5000 monumenten niet ingedeeld in een categorie. Voor gebruikers van het systeem is het erg handig om een onderverdeling te kunnen maken in de monumenten aan de hand van categorie\"en en dan is het vanzelfsprekend erg vervelend als men hierdoor $\pm$ 5000 misloopt. CultuurApp heeft aan de hand van textuele analyse van de omschrijvingen van de monumenten waarvan de categorie reeds bekend was alle monumenten zonder categorie ingedeeld in een categorie.
	
	\subsection{Real-time visuele/textuele berekingen zijn duur}
	Het vergelijken van monumenten aan de hand van foto's voor visuele en omschrijvingen voor textuele analyse is een zeer duur proces. De features die nodig zijn om foto's met elkaar te vergelijken, kunnen alleen worden verkregen met wiskundige software als bijvoorbeeld MATLAB en zelfs dan duurt het nog enkele seconden per foto. Het indelen van omschrijvingen in tags duurt ook enkele seconden per omschrijving en kan daarom ook niet real-time worden gedaan bij het vergelijken van monumenten. De informatie die nodig is om deze vergelijkingen uit te voeren, zal vooraf moeten worden opgeslagen, zodat tijdens het vergelijken louter getallen met elkaar hoeven te worden vergeleken.

%
%
% OPLOSSINGEN
%
%
\section{Oplossingen / Highlights}
	\subsection{Textuele analyse}
	Ieder monument heeft een beschrijving. De lengte van de beschrijving verschilt per monument en is veelal tussen de 5 en 200 woorden. Uit een dergelijk grote dataset van $\pm$ 25.000 monumenten kan interessante data worden herleid.

		\subsubsection{Trefwoorden}
		Een tekst is voor een gebruiker vaak te lang om te lezen. Een gebruiker wil bij het zien van een monument direct weten wat voor monument het is. Trefwoorden bieden hierbij een uitkomst. Het handmatig aanmaken van trefwoorden voor ieder monument is tijdrovend. Hiervoor is een algoritme gebruikt.
		
		\subsubsection{Term Frequency Inverse Document Frequency}
		Term Frequency Inverse Document Frequency (TF-IDF) geeft elk woord in een tekst een bepaalde waarde. Deze waarde is een afweging tussen twee waarden. Hoe hoger de totaalwaarde is, hoe hoger de score voor het woord is. De berekening van de waarde bestaat uit twee delen. Term Frequency is het aantal keer dat een woord in een tekst voor komt. Wanneer "klokgevel" driemaal in een beschrijving van een monument voor komt, zal voor dat monument "klokgevel" een belangrijk trefwoord zijn. Term Frequency wordt berekend door het aantal keer dat het woord voorkomt in de beschrijving te delen door het totaal aantal woorden in de beschrijving. Ieder woord $w$ in beschrijving $x$ heeft de volgende Term Frequency:
		
		\begin{equation}
			TF_w = \frac{\text{occ}_w}{\text{count}_x}
		\end{equation}
		
		\noindent Met:
		\begin{center}
			\begin{tabular}{ c | l }
				TF$_w$ & Term Frequency van woord $w$. \\
			  	occ$_w$ & Aantal voorkomens van het woord $w$ in de beschrijving. \\
			  	count$_x$ & Totaal aantal woorden in de beschrijving $x$. 
			\end{tabular}
		\end{center}
		
		Het tweede deel is Inverse Document Frequency (IDF). Dit is invers evenredig met bij hoeveel monumenten het woord voor komt. Wanneer een woord bij veel monumenten voor komt, is het een minder specifiek trefwoord. Stopwoorden worden op deze manier ook automatisch gefilterd. De Inverse Document Frequency van woord $w$ wordt berekend door de log te nemen van het totaal aantal monumenten gedeeld door het aantal monumenten waar het woord voor komt. 
		
		\begin{equation}
			IDF_w = \log\left({\frac{\text{total}}{\text{subset}_w}}\right)
		\end{equation}
		
		\noindent Met:
		\begin{center}
			\begin{tabular}{ c | l }
				IDF$_w$ & Inverse Document Frequency van woord $w$. \\
			  	total & Totaal aantal beschrijvingen (monumenten). \\
			  	subset$_w$ & Aantal beschrijvingen (monumenten) waar woord $w$ in voorkomt.
			\end{tabular}
		\end{center}
		
		Aan de hand van dit algoritme heeft CultuurApp alle woorden van alle beschrijvingen van alle monumenten geanalyseerd en waarden gegeven. CultuurApp maakt live berekeningen en extraheert geautomatiseerd sleutelwoorden uit de beschrijving door voor ieder woord in de beschrijving van het monument een TFIDF waarde te berekenen en de woorden met de hoogste score worden als sleutelwoord aangewezen. De Term Frequency en Inverse Document Frequency worden door deze te vermenigvuldigen \'e\'en waarde:
		
		\begin{equation}
			\text{TF-IDF}_w =\frac{\text{occ}_w}{\text{count}_x} \cdot  \log\left({\frac{\text{total}}{\text{subset}_w}}\right)
		\end{equation}
		
		\noindent Met:
		\begin{center}
			\begin{tabular}{ c | l }
				occ$_w$ & Aantal voorkomens van het woord $w$ in de beschrijving. \\
			  	count$_x$ & Totaal aantal woorden in de beschrijving $x$.\\
				total & Totaal aantal beschrijvingen (monumenten). \\
			  	subset$_w$ & Aantal beschrijvingen (monumenten) waar woord $w$ in voorkomt.
			\end{tabular}
		\end{center}
		
		Per woord in een beschrijving berekent CultuurApp de TF-IDF waarde. De top vijf woorden met de hoogste TF-IDF waarde worden door CultuurApp aangewezen als tags (trefwoorden). Deze trefwoorden\label{trefwoorden_berekening} toont CultuurApp op de monumentpagina.
		
		\subsubsection{Tag-cloud}
		Gebruikers weten vaak niet waar ze naar op zoek zijn. Een tagcloud kan hierbij uitkomst bieden. De gebruiker ziet in \'e\'en oogopslag een aantal tags staan en ziet direct hoe belangrijk deze tags zijn. CultuurApp heeft van alle woorden van alle beschrijvingen van alle monumenten een gemiddelde TF-IDF waarde vastgesteld relatief naar de monumenten. Dit door bij ieder voorkomen van een woord zijn TF-IDF waarde te berekenen en hiervan een gemiddelde te nemen. Bij ieder voorkomen van een woord bij een monument is de gemiddelde TF-IDF waarde bijgeschaald. Alle woorden hebben hierdoor een uiteindelijke score gekregen. 
		
		\begin{equation}
			\overline{\text{TF-IDF}_w} =\frac{\sum \left\{ \frac{\text{occ}_w}{\text{count}_x} \cdot  \log{\left(\frac{\text{total}}{\text{subset}_w}}\right)\right\}}{subset_w}
		\end{equation}
		
		\noindent Voor ieder monument $x$ waar woord $w$ voorkomt, met:
		
		\begin{center}
			\begin{tabular}{ c | l }
				$x$ & monument waar woord $w$ in de beschrijving staat.\\
				occ$_w$ & Aantal voorkomens van het woord $w$ in de beschrijving. \\
			  	count$_x$ & Totaal aantal woorden in de beschrijving $x$.\\
				total & Totaal aantal beschrijvingen (monumenten). \\
			  	subset$_w$ & Aantal beschrijvingen (monumenten) waar woord $w$ in voorkomt.\\
			$\overline{\text{TF-IDF}_w}$ & Gemiddelde TF-IDF waarde van woord $w$.
			
			\end{tabular}
		\end{center}
		
		Door willekeurig bovengemiddelde waarden te pakken uit de set, kan een tagcloud worden gemaakt. Alleen woorden met een TF-IDF waarde hoger dan gemiddeld worden getoond, hierdoor worden stopwoorden gefilterd. Woorden met een hogere score krijgen een groter lettertype.
		
		\subsubsection{Gerelateerde monumenten}
		Ieder monument heeft steekwoorden. Hoe groter de interceptie van de steekwoorden van twee verschillende monumenten is, hoe groter de kans is dat deze monumenten bij elkaar horen. CultuurApp zoekt bij een monument welke andere monumenten zoveel mogelijk tags (trefwoorden)[\ref{trefwoorden_berekening}] overeen hebben, om op deze manier gerelateerde monumenten te bepalen.

	\subsection{Visuele analyse}		
		\subsubsection{Feature Extraction}
		Om de foto's van de monumenten visueel te analyseren, zullen er eerst features uit de foto's moeten worden ge\"extraheerd. In de ori\"entatiefase dachten we genoeg te hebben aan een plugin voor het programma ImageJ, maar uiteindelijk hebben we toch gekozen voor een geavanceerdere tool. Uit de foto's zijn nu 399 features verkregen met behulp van het MATLAB-script FeatureExtractor (zie reference \cite{5}). De FeatureExtractor verkrijgt de volgende features:
		\begin{enumerate}
			\item Het gemiddelde, de mediaan, de standaard deviatie, de scheefheid, de kurtosis, het minimum en het maximum van de helderheid.
			\item Bin 1-8 van een 8-bin grijswaarde histogram.
			\item Bin 1-32 van een 32-bin grijswaarde histogram.
			\item Het gemiddelde, de mediaan, de standaard deviatie, de kurtosis, het minimum en het maximum van de kleuren rood, groen en blauw.
			\item Meest dominante kleur na 16-color adaptive quantization.
			\item Op \'e\'en na meest dominante kleur na 16-color adaptive quantization.
			\item Bin 1-4 en 1-8 van een 4-bin en 8-bin histogram in de kleuren rood, groen en blauw.
			\item Het gemiddelde, de mediaan, de standaard deviatie, de scheefheid, de kurtosis, het minimum en het maximum van de tint en verzadiging.
			\item Bin 1-4 en 1-8 van een 4-bin en 8-bin histogram van de tint en verzadiging.
			\item Enkele waardes m.b.t. contrast, homogeneiteit, energie en ratio van rand-pixels tot de grootte van de afbeelding.
			\item Enkele waardes m.b.t. entropie.
		\end{enumerate}
		Al deze features worden door de FeatureExtractor opgeslagen in de volgende bestanden: dev\_acq.txt, dev\_gabor.txt, dev\_hsv.txt, dev\_light.txt, dev\_log.txt, dev\_rgb.txt, dev\_segment.txt, dev\_spatial.txt en dev\_texture.txt. We hebben er bewust voor gekozen ons niet te verdiepen in de verkregen waardes en wat deze precies betekenen.
		
		\subsubsection{Importeren}
		De bestanden verkregen bij de Feature Extration kunnen door de CultuurApp worden uitgelezen en in de database ge\"importeerd. Om daadwerkelijk iets aan deze waarden te hebben, moeten ze worden genormaliseerd. De CultuurApp doet dit door de waarden lineair te normaliseren (zie reference \cite{1}) met de volgende formule:
		\begin{equation}
			n_{fm} = \frac{v_{fm} - \max(v_{f})}{\max(v_{f}) - \min(v_{f})}
		\end{equation}
		
		\noindent Met:
		\begin{center}
			\begin{tabular}{ c | l }
				$v_{fm}$ & de waarde van feature $f$ van monument $m$.\\
				$v_{f}$ & de waardes van de monumenten bij feature $f$.\\
				$n_{fm}$ & de genormaliseerde waarde van feature $f$ van monument $m$.
			\end{tabular}
		\end{center}
		
		\subsubsection{Vergelijking van monumenten}
		Als we de features verkregen door de FeatureExtractor met elkaar willen vergelijken, beschouwen we de 399 features als een vector en kunnen we deze vergelijken met behulp van een zogenaamde Euclidian Distance. Omdat in de Euclidian Distance een voor onze vergelijking onnodige wortel-functie owrdt gebruikt, hebben we deze weggelaten in de functie om de afstanden tussen de monumenten te berekenen. Een normale Euclidian Distance ziet er dus als volgt uit:
		\begin{equation}
			ed(q, p) = \sqrt{(q_1 - p_1)^2 + (q_2 - p_2)^2 + \cdot\cdot\cdot + (q_n - p_n)^2}
		\end{equation}
		De functie die CultuurApp gebruikt om de afstand tussen twee monumenten te berekenen ziet er als volgt uit:
		\begin{equation}
			ed(q, p) = (q_1 - p_1)^2 + (q_2 - p_2)^2 + \cdot\cdot\cdot + (q_n - p_n)^2
		\end{equation}
		Beide vergelijkingen gebruiken de volgende variabelen:
		\begin{center}
			\begin{tabular}{ c | l }
				$q$/$p$ & vectoren van de 399 features van monument $q$ of $p$.\\
				$q_{i}$/$p_{i}$ & feature $i$ van monument $q$ of $p$.\\
				$n$ & het totaal aantal features per monument.
			\end{tabular}
		\end{center}
		
		Door een bepaald monument $q$ te noemen en alle monumenten langs te gaan en deze $p$ te noemen, kunnen we de afstanden tussen $q$ en de andere monumenten vinden. Het monument met de kleinste afstand is het meest 'visueel gelijkend'.
		
	\subsection{Completeren dataset}
	Bij $\pm$ 5000 monumenten is geen hoofd- en subcategorie bekend. Voor het gebruiksgemak is het gewenst dat deze categorie\"en worden ingevuld. Aan de hand van visuele en textuele analyse zou dit mogelijk moeten zijn, gezien het feit dat we beschikken over $\pm$ 20000 monumenten die wel een hoofd- en subcategorie bevatten.
	
		\subsubsection{Visueel}
		In eerste instantie was het idee om met behulp van visuele analyse van de foto's van monumenten alle monumenten zonder categorie in te delen in een bepaalde categorie aan de hand van de visuele eigenschappen van de monumenten die wel een categorie bevatten. Helaas werd vrij snel duidelijk dat visuele eigenschappen van monumenten zelden iets zeggen over de categorie waarin een monument zou moeten vallen. Zo wordt een watertoren aan de hand van compositie, kleur en textuur gemakkelijk ingedeeld in de categorie 'Kastelen', waar deze oorspronkelijk was ingedeeld in de categorie 'Overheidsgebouwen'. Zo heeft CultuurApp het eigenlijk niet echt 'verkeerd', maar zijn de selectiecriteria voor het indelen van een monument in een categorie niet gebaseerd op visuele eigenschappen. Hierdoor is het nooit gelukt om CultuurApp een percentage hoger dan 20\% 'goed bepaalde' categorie\"en te verkrijgen.
	
		\subsubsection{Tekstueel}
		Voor de tekstuele analyse gebruikt CultuurApp een aangepaste vorm van TF-IDF. Voor iedere woord voor iedere beschrijving voor ieder gecategoriseerd monument heeft CultuurApp opgeteld hoevaak het woord voor komt per categorie. Dit levert een grote, onduidelijke en onbruikbare set data op. Aan de hand van TF-IDF relatief tot de categori\"en kan deze set data enorm bruikbaar worden. Hoe vaker een woord voorkomt bij een categorie, hoe waarschijnlijker het is dat een woord een categorie voorspelt. Maar wanneer een woord bij alle categori\"en vaak voorkomt, is het onwaarschijnlijk dat het woord is toe te wijzen aan een categorie. Het aantal voorkomens van een woord bij een categorie wordt gedeeld door het totaal aantal voorkomens van het woord. Dit is het TF gedeelte van de berekening. Komt een woord bij alle categori\"en vaak voor, dan is het een te algemeen woord. Hier komt het IDF gedeelte weer van toepassing. De log van het totaal aantal gecategoriseerde monumenten gedeeld door het totaal aantal keer dat een woord voorkomt. Deze waarden worden vermenigvuldigd en er is nu een score bepaald. Nu heeft ieder woord, per categorie, een score.
		
		\begin{equation}
		\text{TF-IDF}_m^i = \sum_{w=1}^5\frac{occ_{wi}}{\text{occ}_w} \cdot log\left(\frac{count_x}{\text{occ}_w}{\text{occ}_w}\right)
		\end{equation}
		
		\noindent Voor ieder woord $w$ voorkomend in categorie $i$ met:
		
		\begin{center}
			\begin{tabular}{ c | l }
				$m$ & Ongecategoriseerd monument $m$.\\
				$w$ & De top 5 ge\"extraheerde tags.\\
				$i$ & Iedere categorie waar woord $w$ voorkomt.\\
				occ$_{wi}$ & Aantal voorkomens van het woord $w$ in categorie $i$. \\
			  	occ$_{w}$ & Aantal voorkomens van het woord $w$.\\
				count$_x$ & Totaal aantal gecategoriseerde monumenten.\\
				TF-IDF$_m^i$ & TF-IDF waarde monument $m$ voor categorie $i$.
			
			\end{tabular}
		\end{center}

	
	Wanneer een ongecategoriseerd monument gecategoriseerd moet worden, extraheert CultuurApp zoals beschreven tags (keywords) uit de tekst. Voor ieder van deze sleutelwoorden, die de belangrijkste woorden zijn van de tekst, wordt per categorie berekend wat de waarschijnlijkheid is dat een monument tot een categorie behoort. Dit gebeurt door de TF-IDF waarde van de tag te vermenigvuldigen met de TF-IDF waarde van de tag relatief tot de categorie. Deze waarden worden voor de tags opgeteld, zodat een totaalscore is bepaald per categorie. 
	
	\begin{equation}
		\text{Categorie}: max_i\left(\sum_{w=1}^5 \text{TF-IDF}_m^i \cdot \overline{\text{TF-IDF}_w}\right) 
	\end{equation}
	\begin{center}
	$=$
	\end{center}
	
	\begin{equation}
	max_i\left(\sum_{w=1}^5\frac{occ_{wi}}{\text{occ}_w} \cdot log\left(\frac{count_x}{\text{occ}_w}\right)\cdot \frac{\sum \left\{ \frac{\text{occ}_w}{\text{count}_x} \cdot  \log{\left(\frac{\text{total}}{\text{subset}_w}}\right)\right\}}{subset_w}
 \right)
		\end{equation}
	
	\noindent Voor iedere categorie $i$ en de top 5 tags $w$ met:
	
	\begin{center}
			\begin{tabular}{ c | l }
				$m$ & Ongecategoriseerd monument $m$.\\
				$w$ & De top 5 ge\"extraheerde tags.\\
				$i$ & Iedere categorie waar woord $w$ voorkomt.\\
				total & Totaal aantal monumenten.\\
				$\text{subset}_w$ & Aantal monumenten waar woord $w$ voor komt.\\
				occ$_{wi}$ & Aantal voorkomens van het woord $w$ in categorie $i$. \\
			  	occ$_{w}$ & Aantal voorkomens van het woord $w$.\\
				count$_x$ & Totaal aantal gecategoriseerde monumenten.\\
				TF-IDF$_m^i$ & TF-IDF waarde monument $m$ voor categorie $i$.\\
			$\overline{\text{TF-IDF}_w}$ & Gemiddelde TF-IDF waarde van woord $w$.
		
			
			\end{tabular}
		\end{center}
	
	\noindent CultuurApp kijkt nu welke categorie $i$ de hoogste score haalt en het meest waarschijnlijk is. Deze categorie wordt toegewezen aan het monument.
	
	Door bij een monument waarvan de categorie bekend is de categorie 'te vergeten' en daarna de categorie te voorspellen, is het mogelijk om de juistheid van de voorspelling te controleren. Aan de hand van tekstuele analyse is het CultuurApp gelukt om 86\%, dus $\pm$ 19200 van de categorie\"en van de gecategoriseerde monumenten juist te voorspellen.
		
	\subsection{Aanbevelingen}
	Toeristen zoeken naar monumenten die ze interessant vinden, maar willen daarbij ook geprikkeld worden. Monumenten ontdekken, zichzelf verrijken met monumenten die ze zelf niet zouden kunnen vinden. Hiervoor zijn aanbevelingen de uitkomst. Binnen CultuurApp zijn twee plaatsen waar aanbevelingen worden gegeven, namelijk op de profielpagina en bij een monument dat wordt bekeken:
	
		\subsubsection{Algemeen}
		Om aanbevelingen ten kunnen doen, moet er bepaalde informatie worden onthouden door CultuurApp. Van iedere toerist wordt informatie als zoekwoorden, geselecteerde categorie\"en, gezochte steden e.d. opgeslagen. Daarnaast wordt ook opgeslagen welke monumenten een toerist uiteindelijk bezoekt. Deze informatie wordt opgeslagen in de database en gelinkt aan de 'computer' van de gebruiker. Deze informatie wordt nooit verwijderd en op het moment dat de gebruiker inlogt op de computer, wordt de informatie gekoppeld aan zijn profiel. Door deze informatie is het mogelijk om bijvoorbeeld een set monumenten te verkrijgen welke door de toerist of CultuurApp-gebruiker zijn bezocht. Deze informatie is erg bruikbaar bij het geven van aanbevelingen.
	
		\subsubsection{Profielpagina}
		Bij de profielpagina wordt gebruik gemaakt van de set monumenten die door de toerist of CultuurApp-gebruiker is bezocht op de website. Deze set wordt vergeleken met alle sets van monumenten in de dtabase. De set met het meeste overeenkomsten met de set van de aan te bevelen toerist of CultuurApp-gebruiker, wordt gebruikt om aanbevelingen te geven. Dit wordt gedaan met het volgende algoritme:
		\begin{enumerate}
			\item Zoek de set van monumenten van de aan te bevelen toerist of CultuurApp-gebruiker, noem deze $A$.
			\item Loop door de sets monumenten van alle gebruikers heen, noem een zo'n set $B$ en sla de score $s = |A \cap B|$ op in $C$ als $C\left[s\right] = B$.
			\item Sorteer de set op score van hoog naar laag en haal de eerste set op uit $C$ en noem deze $D$.
			\item Verwijder nu de monumenten van $A$ uit $D$ en sla deze op in $E$, oftewel $E = D - A$.
			\item Beveel op willekeurige volgorde monumenten uit $E$ aan aan de toerist of CultuurApp-gebruiker.
		\end{enumerate}
		
		\subsubsection{Monumentpagina}
		Bij de monumentpagina wordt gebruikt gemaakt van alle sets monumenten per gebruiker die in de database staan. Hierbij wordt gekeken welke set(s) monumenten het monument bevat dat de gebruiker op dit moment bekijkt. Vervolgens worden de rest van de monumenten in deze set gebruikt om de gebruiker een aanbeveling te geven.
		\begin{enumerate}
			\item Noem het monument waarbij aanbevelingen moeten worden gedaan $m$.
			\item Zoek de set van monumenten van de aan te bevelen toerist of CultuurApp-gebruiker, noem deze $A$.
			\item Selecteer de sets monumenten van alle gebruikers die monument $m$ bevatten, noem deze $Q$.
			\item Loop door $Q$ heen, noem een set uit $Q$ steeds $B$ en sla de score $s = \left|A \cap B\right|$ op in $C$ als $C\left[s\right] = B$.
			\item Sorteer $C$ aflopend op score, haal de eerste set op en noem deze $D$.
			\item Verwijder nu de monumenten van $A$ (deze bevat ook monument $m$) uit $D$ en sla deze op in $E$, oftewel $E = D - A$.
			\item Beveel op willekeurige volgorde monumenten uit $E$ aan aan de toerist of CultuurApp-gebruiker.
		\end{enumerate}
	
	\subsection{Externe informatiebronnen}
		CultuurApp maakt gebruik van enkele externe informatiebronnen om bijvoorbeeld het weer en de faciliteiten uit de omgeving van een monument te  weergeven. Externe informatiebronnen zijn handig, maar gevaarlijk voor de betrouwbaarheid van het systeem, omdat ze bijvoorbeeld tijdelijk onbereikbaar kunnen zijn. Voor het gebruik van deze bronnen zijn verschillende systeemcomponenten geschreven, waardoor deze externe bronnen altijd op dezelfde manier benaderd en gecached worden. Een externe informatiebron wordt nooit $\pm$ 25.000 keer achter elkaar aangroepen om de informatie van alle monumenten in \'e\'en keer op te slaan. In plaats daarvan wordt op het moment dat een toerist een bepaald monument bekijkt alle informatie indien nodig live van de externe informatiebronnen opgehaald en direct opgeslagen in de database (caching). Dit zorgt ervoor dat er de volgende keer dat deze informatie wordt opgevraagd geen contact nodig is met de externe informatiebron. Het aantal dagen dat informatie opgeslagen blijft, verschilt per informatiebron, maar is nooit oneindig, omdat de externe informatiebronnen variabel zijn.
	
		\subsubsection{Wunderground}
		Met de API van Wunderground (zie reference \cite{2}) is het mogelijk om aan de hand van een longitude en latitude een weersvoorspelling te verkrijgen in. Omdat het weer binnen een stad in Nederland redelijk constant is, hebben we besloten om het weer per stad te cachen. Weersvoorspellingen worden per dag per stad gecached, waardoor voor iedere stad het weer dus \'e\'en keer per dag moet worden opgehaald.
	
		\subsubsection{Google Places}
		Met de API van Google Places (zie reference \cite{3}) is het mogelijk om aan de hand van een longitude, latitude en enkele steekwoorden de juiste faciliteiten rond een monument op te halen. Omdat het aantal faciliteiten rondom een monument zelden veradnerd (er wordt binnen \'e\'en dag namelijk niet zomaar een restaurant opgebouwd), hebben we er voor gekozen om voor ieder monument de faciliteiten voor 15 dagen op te slaan in de database. Zo is het per monument slechts \'e\'en keer in de 15 dagen nodig om de faciliteiten rondom een monument op te halen. De faciliteiten rond een monument worden tot 5 km rondom het monument opgehaald en weergegeven op aflopende volgorde qua rating en daarna op oplopende volgorde qua afstand, waardoor een toerist altijd de beste en dichtbijzijnste bars of restaurants als eerste te zien krijgt.
	
		\subsubsection{Flickr}
		Met de API van Flickr (zie reference \cite{4}) is het mogelijk om aan de hand van een longitude, latitude en een zoekwoord foto's van de omgeving van een monument op te halen. Als zoekwoord geeft CultuurApp altijd de naam van de stad waarin het monument zich bevindt op, zodat een zo compleet beeld wordt gegeven van de omgeving van het monument. De URLs van foto's van Flickr worden opgeslagen voor 10 dagen per monument. Zo is het per monument slechts \'e\'en keer per 10 dagen nodig om de nieuwe URLs van de foto's op te halen. Toeristen krijgen hierdoor altijd een up-to-date beeld van de omgeving.
		
\section{Testen van het systeem}
Omdat in de ontwerp fase besloten is 'test driven design' te gaan toepassen bij het ont\-wikkelen van CultuurApp zijn voor alle individuele functies unit tests gemaakt. Deze unit tests testen van elke functie of zij de gewenste output geven en of zij het gewenste resultaat bereiken met betrekking tot de database. Dit geldt vooral bij de randvoorwaarden van de functies. Omdat het natuurlijk niet gewenst is dat de tests de database van het live systeem aanpassen en omdat de resultaten van de tests op de functies goed te voorspellen moeten zijn maken de tests geen gebruik van de ontwikkel of live database maar van een speciale test database. Omdat de tests elkaar via deze database zouden kunnen be\"invloeden wordt deze database voor elke test geleegd en opnieuw opgebouwd voordat deze wordt uitgevoerd. \\
\\
Voor het testen van alle functies is gebruik gemaakt van het systeem phpunit. Hierin is voor elke klasse waarin zich functies bevinden een phpunit test case gemaakt. Deze test cases bevatten test functies welke de functies van de de te teste klasse test.\\
\\
Om goed bij te houden welke functies en klassen allemaal wel en niet getest zijn is gebruik gemaakt van line coverage. In figuur \ref{classes} is een overzicht te vinden van de line coverage door onze test cases.\\
\begin{figure}[ht!]
	\centering
	\includegraphics[width=\textwidth]{classes.png}
	\caption{Line coverage in de geschreven klassen \label{classes}}
\end{figure}
Zoals te zien is zijn niet alle klassen volledig gedekt door de line coverage. Dit heeft verschillende oorzaken. Bij het ontwikkelen van CultuurApp is gebruik gemaakt van het systeem Kohana. Door de werking van Kohana is het soms niet mogelijk vanuit een testcase bepaalde attributen of functies te bereiken waardoor deze niet door ons getest konden worden. De meeste van deze functies worden echter al door Kohana zelf getest. Ook word in sommige klassen de voorwaarde gesteld of bepaalde php extensions of apache modules geladen zijn. De else functies van deze voorwaarden kunnen niet getest worden aangezien hiervoor de betreffende module of extensie zou moeten worden uitgeschakeld en de web server opnieuw opgestart zou moeten worden.
		
\section{Reflectie op het teamwork}

	\subsection{Voorbereidingsfase}
	Tijdens het maken van de Requirements Analysis, de Architectural Design en het Test and Implementation Plan is vooraf veel overleg gepleegd. Alle mogelijkheden zijn besproken en er is gezamelijk een selectie requirements uitgekomen. Bij het maken van deze rapporten waren de verwachtingen in het begin onduidelijk. De drafts die we van deze rapporten hebben ingeleverd waren daarom geen goede stukken om feedback op te krijgen, waardoor ook de finals van deze rapporten matig waren. Uiteindelijk hebben we de kans gekregen om deze finals samen met alle andere groepen binnen ons Contextproject te verbeteren, maar hierdoor is wel tijd die eigenlijk bij de ontwikkelfase hoorde verloren gegaan.
	
	\subsection{Ontwikkelfase}
	De ontwikkelfase ging bij de eerste iteratie erg hard, maar dit was noodzakelijk, omdat we veel tijd verloren waren aan de voorbereidingsfase. De taken werden onderverdeeld en individuele software werd automatisch gekoppeld door vooraf vastgestelde eigenschappen. In de hierop volgende iteraties bleek het regelmatig nodig te zijn code uit de eerste iteratie te verbeteren. Te implementeren features werden complexer en voortgang werd trager. Iedere week hebben we echter een deadline voor onszelf gesteld. Wanneer taken niet afgemaakt werden tijdens de bijeenkomsten, werd thuis verder gewerkt. Er is vele malen meer tijd in het project komen te zitten dan voorgeschreven was. Dit doordat de groepsgenoten allen gedreven zijn, trots zijn op wat ze doen en dit een interessant project was. Het cre\"eeren van data maakt veel mogelijk en deze nieuwe mogelijkheden zijn interessant om te ontdekken. Tijdens bijeenkomsten is alles overlegd en ideeen uitgewisseld. Bij het onmogelijk blijken van features zijn oplossingen besproken en geimplementeerd. Door regelmatige afwezigheid en/of te laat komen van een van de groepsgenoten zijn irritaties ontstaan. Deze irritaties zijn uitgepraat en de taakverdeling is hierop afgesteld. 
	
	\subsection{Taakverdeling}
	\begin{tabular}{l || c | c | c | c}
  		Feature&					Tim&Herman&Rutger&Sjoerd\\
  		\hline
  		\hline						%	T   H   R   S
  		Kaart-weergave&					  & x & x &   \\
  		Lijst-weergave&					x & x & x & x \\
  		Detail-weergave&				  & x &   & x \\
  		Filtering en zoeken&			  & x & x & x \\
  		Sortering&						  & x & x & x \\
  		Visuele Vergelijking&			  &   &   & x \\
  		Textuele Vergelijking&			  &   & x &   \\
  		Inloggen en registreren&		  & x &   &   \\
  		Foursquare&			  			  & x &   &   \\
  		Flickr&				  			  &   &   & x \\
  		Wunderground&		  			  &   &   & x \\
  		Google Places&		  			  &   &   & x \\
  		Thesauraus&		  				  &   & x &   \\
  		Completeren dataset&	  		  &   & x & x \\
  		Logging&				  		  &   &   & x \\
  		Aanbevelingen \& Populariteit&	  &   &   & x \\
  		Translator&		  				x & x &   &   \\
  		Lay-out&			  			  & x &   &   \\
  		Testing&		  			  	x &   &   &   \\
  		Architectuur&                     & x &   &
  	\end{tabular}

	\subsection{Individuele reflectie op het teamwork}
		
		\subsubsection{Herman Banken}
		Bij het maken van de indeling kon ik helaas niet aanwezig zijn en ik werd dus ingedeeld bij mensen die ik nog niet kende. Dat is best wel een gok voor een dergelijk groot project, maar het is me goed bevallen om met Sjoerd, Rutger en Tim samen te werken. Elk van ons is zeer gedreven om een gaaf product af te leveren en er is dus vaak 's avonds en zelfs 's nachts aan gewerkt. In de vele uren die we samen hebben zitten programmeren hebben zijn we veel problemen tegen gekomen en altijd konden we elkaar helpen.\\
		Ik had enkele idee\"en voor het goede verloop van het project en de implementatie van de applicatie. Gelukkig pakten die idee\"en goed uit en hebben mijn groepsgenoten goed gebruik gemaakt van de mogelijkheden die GIT en Kohana bieden, ook al waren ze vooraf een behoorlijk sceptisch.
		
		\subsubsection{Sjoerd van Bekhoven}
		Bij het indelen van de groepen werd, zoals toen werd gezegd, geen rekening gehouden met het aantal punten of het aantal jaren dat je gestudeerd had. Toch bleek dat onze groep voornamelijk bestond uit zogenaamde 'langstudeerders', waar ik er zelf ook \'e\'en van ben. Uiteindelijk viel \'e\'en persoon van deze groep af en kwam Herman bij ons terecht. Hoewel ik er in het begin redelijk sceptisch instond, heb ik nauwelijks last gehad van het feit dat onze groep bestond uit oudere (en dus minder goed studerende) studenten. De groep fungeerde vrij soepel en vergaderen was zelden nodig. Tims regelmatige te laat komen en afwezig zijn heeft op een gegeven moment tot veel irritatie geleid. Hij heeft dit enigszins rechtgetrokken door extra gas te geven tegen het einde. Rutger heeft zich ontplooid als harde werker en vindt het geen probleem om ook thuis even door te werken. Herman fungeerde als techneut en heeft ons aardig wat 'moeilijke, maar wel heel handige' snufjes aangereikt, wat op sommige momenten tot problemen leed, maar ons ook ontzettend veel heeft opgeleverd. Kortom: de groep was voornamelijk prettig en ik ben erg tevreden met het resultaat dat we bereikt hebben.
		
		\subsubsection{Tim Eversdijk}
		Afgelopen half jaar heb ik met plezier samen mogen werken met Rutger, Sjoerd en Herman. In het eerste kwartaal, tijdens de ontwikkel fase, viel het me op dat iedereen zeer gemotiveerd was een uitgebreid, goed, fancy en realistisch systeem te ontwerpen. Gelukkig zette deze motivatie zich ook door toen we in het 2e kwartaal de ontwikkel fase in gingen. Jammer genoeg is het meerdere malen voorgekomen dat ik niet op tijd aanwezig was en in combinatie met wat slechte communicatie vanaf mijn kant heeft dit wat terechte irritaties opgewekt. Hier hebben we het onderling over gehad en uitgepraat.\\
		Zelf ben ik tijdens de ontwikkel fase vooral bezig geweest met het testen van het systeem. Dit vond ik lastiger dan ik van te voren had gedacht. Dit kwam voornamelijk doordat ik nog nooit met de betreffende systemen, Kohana en PHPUnit, had gewerkt.
		
		\subsubsection{Rutger Plak}
		Het was fijn om in deze projectgroep te zitten. De groepsgenoten waren, zoals helaas vaak niet zo is in willekeurige projectgroepen, even gedreven, gemotiveerd en enthousiast als ik. Tijdens de onderzoeksfase is dan ook vaak in groepsverband tot in de late uren doorgewerkt. Door deze gedrevenheid hebben wij tijdens de implementatiefase alles gedaan wat we wilden doen. Herman Banken bewaarde het overzicht over het systeem. Dit is erg handig omdat bij een systeem dat zo snel groeit vaak het vinden van een kleine component lastig kan zijn. Sjoerd van Bekhoven nam de lastige taak van visuele analyse op zich. Hij was hier vaak thuis mee bezig en heeft dan ook een indrukwekkend visueel vergelijkingssysteem neergezet.
\clearpage
\begin{thebibliography}{99}
\bibitem{1} Selim Aksoy and Robert M. Haralick, \textsl{Feature normalization and likelihood-based similarity measures for image retrieval}, 2001
\bibitem{2} http://www.wunderground.com/weather/api/
\bibitem{3} https://developers.google.com/maps/documentation/places/
\bibitem{4} http://www.flickr.com/services/api/
\bibitem{5} http://code.google.com/p/softwarestudies/wiki/FeatureExtractor
\end{thebibliography}		
\end{document}